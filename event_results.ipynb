{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c66b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_model\n",
    "from run_model import run_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f41acfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"domain\" # choose checkpoint type\n",
    "model_checkpoints = {\n",
    "    \"fast\": \"distilbert-base-uncased\",\n",
    "    \"base\": \"bert-base-uncased\",\n",
    "    \"domain\": \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e415be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning data preprocessing\n",
      "Processed data written to event_tokens200_train_for_token_classification.json and event_tokens200_dev_for_token_classification.json\n",
      "Train label distribution:\n",
      "NoDisposition: 4509\n",
      "Disposition: 1118\n",
      "Undetermined: 455\n",
      "Dev label distribution:\n",
      "NoDisposition: 723\n",
      "Disposition: 199\n",
      "Undetermined: 84\n",
      "Loading dataset into huggingface format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e9bd1d4ae83fbb9d\n",
      "Reusing dataset json (/home/brentdevries/.cache/huggingface/datasets/json/default-e9bd1d4ae83fbb9d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38aa755a45be443f9a9cb50b4769e364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets using BERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/brentdevries/.cache/huggingface/datasets/json/default-e9bd1d4ae83fbb9d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-20fd6332e7dd221a.arrow\n",
      "Loading cached processed dataset at /home/brentdevries/.cache/huggingface/datasets/json/default-e9bd1d4ae83fbb9d/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-6a456e2216052494.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BERT token classification model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running training *****\n",
      "  Num examples = 1052\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 3300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model sent to cuda\n",
      "Setting up training configuration\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3300' max='3300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3300/3300 1:07:24, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.083361</td>\n",
       "      <td>0.432161</td>\n",
       "      <td>0.432161</td>\n",
       "      <td>0.346827</td>\n",
       "      <td>0.432161</td>\n",
       "      <td>0.360438</td>\n",
       "      <td>0.432161</td>\n",
       "      <td>0.328786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.071671</td>\n",
       "      <td>0.478392</td>\n",
       "      <td>0.478392</td>\n",
       "      <td>0.353498</td>\n",
       "      <td>0.478392</td>\n",
       "      <td>0.365508</td>\n",
       "      <td>0.478392</td>\n",
       "      <td>0.346529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.055246</td>\n",
       "      <td>0.551759</td>\n",
       "      <td>0.551759</td>\n",
       "      <td>0.379129</td>\n",
       "      <td>0.551759</td>\n",
       "      <td>0.383202</td>\n",
       "      <td>0.551759</td>\n",
       "      <td>0.378703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.034061</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0.401905</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0.387109</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>0.390617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.011734</td>\n",
       "      <td>0.644221</td>\n",
       "      <td>0.644221</td>\n",
       "      <td>0.407800</td>\n",
       "      <td>0.644221</td>\n",
       "      <td>0.380408</td>\n",
       "      <td>0.644221</td>\n",
       "      <td>0.380815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.990274</td>\n",
       "      <td>0.682412</td>\n",
       "      <td>0.682412</td>\n",
       "      <td>0.467314</td>\n",
       "      <td>0.682412</td>\n",
       "      <td>0.399684</td>\n",
       "      <td>0.682412</td>\n",
       "      <td>0.397133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.966494</td>\n",
       "      <td>0.704523</td>\n",
       "      <td>0.704523</td>\n",
       "      <td>0.589309</td>\n",
       "      <td>0.704523</td>\n",
       "      <td>0.423345</td>\n",
       "      <td>0.704523</td>\n",
       "      <td>0.421272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.026800</td>\n",
       "      <td>0.940076</td>\n",
       "      <td>0.723618</td>\n",
       "      <td>0.723618</td>\n",
       "      <td>0.579730</td>\n",
       "      <td>0.723618</td>\n",
       "      <td>0.445751</td>\n",
       "      <td>0.723618</td>\n",
       "      <td>0.439421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.026800</td>\n",
       "      <td>0.910674</td>\n",
       "      <td>0.739698</td>\n",
       "      <td>0.739698</td>\n",
       "      <td>0.631661</td>\n",
       "      <td>0.739698</td>\n",
       "      <td>0.483484</td>\n",
       "      <td>0.739698</td>\n",
       "      <td>0.473179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.026800</td>\n",
       "      <td>0.882573</td>\n",
       "      <td>0.753769</td>\n",
       "      <td>0.753769</td>\n",
       "      <td>0.652502</td>\n",
       "      <td>0.753769</td>\n",
       "      <td>0.536236</td>\n",
       "      <td>0.753769</td>\n",
       "      <td>0.503493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.026800</td>\n",
       "      <td>0.845445</td>\n",
       "      <td>0.758794</td>\n",
       "      <td>0.758794</td>\n",
       "      <td>0.661041</td>\n",
       "      <td>0.758794</td>\n",
       "      <td>0.558030</td>\n",
       "      <td>0.758794</td>\n",
       "      <td>0.513383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.026800</td>\n",
       "      <td>0.815871</td>\n",
       "      <td>0.732663</td>\n",
       "      <td>0.732663</td>\n",
       "      <td>0.627865</td>\n",
       "      <td>0.732663</td>\n",
       "      <td>0.572774</td>\n",
       "      <td>0.732663</td>\n",
       "      <td>0.497358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.026800</td>\n",
       "      <td>0.785554</td>\n",
       "      <td>0.725628</td>\n",
       "      <td>0.725628</td>\n",
       "      <td>0.685101</td>\n",
       "      <td>0.725628</td>\n",
       "      <td>0.581367</td>\n",
       "      <td>0.725628</td>\n",
       "      <td>0.507125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.026800</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.735678</td>\n",
       "      <td>0.735678</td>\n",
       "      <td>0.716525</td>\n",
       "      <td>0.735678</td>\n",
       "      <td>0.593043</td>\n",
       "      <td>0.735678</td>\n",
       "      <td>0.526615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.026800</td>\n",
       "      <td>0.727915</td>\n",
       "      <td>0.765829</td>\n",
       "      <td>0.765829</td>\n",
       "      <td>0.747123</td>\n",
       "      <td>0.765829</td>\n",
       "      <td>0.609059</td>\n",
       "      <td>0.765829</td>\n",
       "      <td>0.562706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.811600</td>\n",
       "      <td>0.704453</td>\n",
       "      <td>0.773869</td>\n",
       "      <td>0.773869</td>\n",
       "      <td>0.760217</td>\n",
       "      <td>0.773869</td>\n",
       "      <td>0.619800</td>\n",
       "      <td>0.773869</td>\n",
       "      <td>0.579689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.811600</td>\n",
       "      <td>0.685538</td>\n",
       "      <td>0.769849</td>\n",
       "      <td>0.769849</td>\n",
       "      <td>0.752631</td>\n",
       "      <td>0.769849</td>\n",
       "      <td>0.630865</td>\n",
       "      <td>0.769849</td>\n",
       "      <td>0.593327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.811600</td>\n",
       "      <td>0.663047</td>\n",
       "      <td>0.774874</td>\n",
       "      <td>0.774874</td>\n",
       "      <td>0.736669</td>\n",
       "      <td>0.774874</td>\n",
       "      <td>0.650559</td>\n",
       "      <td>0.774874</td>\n",
       "      <td>0.623288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.811600</td>\n",
       "      <td>0.642310</td>\n",
       "      <td>0.783920</td>\n",
       "      <td>0.783920</td>\n",
       "      <td>0.749113</td>\n",
       "      <td>0.783920</td>\n",
       "      <td>0.678055</td>\n",
       "      <td>0.783920</td>\n",
       "      <td>0.658477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.811600</td>\n",
       "      <td>0.621311</td>\n",
       "      <td>0.796985</td>\n",
       "      <td>0.796985</td>\n",
       "      <td>0.732915</td>\n",
       "      <td>0.796985</td>\n",
       "      <td>0.695704</td>\n",
       "      <td>0.796985</td>\n",
       "      <td>0.677904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.811600</td>\n",
       "      <td>0.602799</td>\n",
       "      <td>0.801005</td>\n",
       "      <td>0.801005</td>\n",
       "      <td>0.731153</td>\n",
       "      <td>0.801005</td>\n",
       "      <td>0.705644</td>\n",
       "      <td>0.801005</td>\n",
       "      <td>0.688989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.811600</td>\n",
       "      <td>0.589592</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.730615</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.713394</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.694357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.640100</td>\n",
       "      <td>0.575536</td>\n",
       "      <td>0.801005</td>\n",
       "      <td>0.801005</td>\n",
       "      <td>0.738813</td>\n",
       "      <td>0.801005</td>\n",
       "      <td>0.720863</td>\n",
       "      <td>0.801005</td>\n",
       "      <td>0.701967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.640100</td>\n",
       "      <td>0.560104</td>\n",
       "      <td>0.810050</td>\n",
       "      <td>0.810050</td>\n",
       "      <td>0.729202</td>\n",
       "      <td>0.810050</td>\n",
       "      <td>0.737858</td>\n",
       "      <td>0.810050</td>\n",
       "      <td>0.715016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.640100</td>\n",
       "      <td>0.543515</td>\n",
       "      <td>0.811055</td>\n",
       "      <td>0.811055</td>\n",
       "      <td>0.732921</td>\n",
       "      <td>0.811055</td>\n",
       "      <td>0.751112</td>\n",
       "      <td>0.811055</td>\n",
       "      <td>0.725804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.640100</td>\n",
       "      <td>0.532558</td>\n",
       "      <td>0.824121</td>\n",
       "      <td>0.824121</td>\n",
       "      <td>0.736958</td>\n",
       "      <td>0.824121</td>\n",
       "      <td>0.745472</td>\n",
       "      <td>0.824121</td>\n",
       "      <td>0.727504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.640100</td>\n",
       "      <td>0.515484</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.743648</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.765271</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.745937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.640100</td>\n",
       "      <td>0.500821</td>\n",
       "      <td>0.826131</td>\n",
       "      <td>0.826131</td>\n",
       "      <td>0.734075</td>\n",
       "      <td>0.826131</td>\n",
       "      <td>0.760410</td>\n",
       "      <td>0.826131</td>\n",
       "      <td>0.736232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.640100</td>\n",
       "      <td>0.490347</td>\n",
       "      <td>0.841206</td>\n",
       "      <td>0.841206</td>\n",
       "      <td>0.748679</td>\n",
       "      <td>0.841206</td>\n",
       "      <td>0.760274</td>\n",
       "      <td>0.841206</td>\n",
       "      <td>0.746250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.640100</td>\n",
       "      <td>0.469598</td>\n",
       "      <td>0.834171</td>\n",
       "      <td>0.834171</td>\n",
       "      <td>0.733832</td>\n",
       "      <td>0.834171</td>\n",
       "      <td>0.758217</td>\n",
       "      <td>0.834171</td>\n",
       "      <td>0.737753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.461366</td>\n",
       "      <td>0.847236</td>\n",
       "      <td>0.847236</td>\n",
       "      <td>0.754166</td>\n",
       "      <td>0.847236</td>\n",
       "      <td>0.765511</td>\n",
       "      <td>0.847236</td>\n",
       "      <td>0.751985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.452799</td>\n",
       "      <td>0.848241</td>\n",
       "      <td>0.848241</td>\n",
       "      <td>0.765134</td>\n",
       "      <td>0.848241</td>\n",
       "      <td>0.765978</td>\n",
       "      <td>0.848241</td>\n",
       "      <td>0.755727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.449437</td>\n",
       "      <td>0.857286</td>\n",
       "      <td>0.857286</td>\n",
       "      <td>0.783641</td>\n",
       "      <td>0.857286</td>\n",
       "      <td>0.770038</td>\n",
       "      <td>0.857286</td>\n",
       "      <td>0.768040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.436450</td>\n",
       "      <td>0.862312</td>\n",
       "      <td>0.862312</td>\n",
       "      <td>0.787458</td>\n",
       "      <td>0.862312</td>\n",
       "      <td>0.794596</td>\n",
       "      <td>0.862312</td>\n",
       "      <td>0.784787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.431965</td>\n",
       "      <td>0.867337</td>\n",
       "      <td>0.867337</td>\n",
       "      <td>0.795779</td>\n",
       "      <td>0.867337</td>\n",
       "      <td>0.813222</td>\n",
       "      <td>0.867337</td>\n",
       "      <td>0.799613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.426557</td>\n",
       "      <td>0.865327</td>\n",
       "      <td>0.865327</td>\n",
       "      <td>0.789531</td>\n",
       "      <td>0.865327</td>\n",
       "      <td>0.817003</td>\n",
       "      <td>0.865327</td>\n",
       "      <td>0.798141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.427841</td>\n",
       "      <td>0.870352</td>\n",
       "      <td>0.870352</td>\n",
       "      <td>0.808007</td>\n",
       "      <td>0.870352</td>\n",
       "      <td>0.804122</td>\n",
       "      <td>0.870352</td>\n",
       "      <td>0.799941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.408113</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>0.800414</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>0.821211</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>0.806787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.420259</td>\n",
       "      <td>0.876382</td>\n",
       "      <td>0.876382</td>\n",
       "      <td>0.816370</td>\n",
       "      <td>0.876382</td>\n",
       "      <td>0.808290</td>\n",
       "      <td>0.876382</td>\n",
       "      <td>0.805284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.411156</td>\n",
       "      <td>0.878392</td>\n",
       "      <td>0.878392</td>\n",
       "      <td>0.819199</td>\n",
       "      <td>0.878392</td>\n",
       "      <td>0.819728</td>\n",
       "      <td>0.878392</td>\n",
       "      <td>0.813121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.432523</td>\n",
       "      <td>0.887437</td>\n",
       "      <td>0.887437</td>\n",
       "      <td>0.833436</td>\n",
       "      <td>0.887437</td>\n",
       "      <td>0.807500</td>\n",
       "      <td>0.887437</td>\n",
       "      <td>0.813732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.427235</td>\n",
       "      <td>0.893467</td>\n",
       "      <td>0.893467</td>\n",
       "      <td>0.840668</td>\n",
       "      <td>0.893467</td>\n",
       "      <td>0.813806</td>\n",
       "      <td>0.893467</td>\n",
       "      <td>0.821530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.399777</td>\n",
       "      <td>0.884422</td>\n",
       "      <td>0.884422</td>\n",
       "      <td>0.822968</td>\n",
       "      <td>0.884422</td>\n",
       "      <td>0.824817</td>\n",
       "      <td>0.884422</td>\n",
       "      <td>0.819257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.415755</td>\n",
       "      <td>0.883417</td>\n",
       "      <td>0.883417</td>\n",
       "      <td>0.824441</td>\n",
       "      <td>0.883417</td>\n",
       "      <td>0.818564</td>\n",
       "      <td>0.883417</td>\n",
       "      <td>0.815871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.410357</td>\n",
       "      <td>0.868342</td>\n",
       "      <td>0.868342</td>\n",
       "      <td>0.786817</td>\n",
       "      <td>0.868342</td>\n",
       "      <td>0.833919</td>\n",
       "      <td>0.868342</td>\n",
       "      <td>0.804415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.236700</td>\n",
       "      <td>0.416314</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>0.800906</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>0.823790</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>0.807319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.236700</td>\n",
       "      <td>0.435050</td>\n",
       "      <td>0.888442</td>\n",
       "      <td>0.888442</td>\n",
       "      <td>0.831762</td>\n",
       "      <td>0.888442</td>\n",
       "      <td>0.813900</td>\n",
       "      <td>0.888442</td>\n",
       "      <td>0.816776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.236700</td>\n",
       "      <td>0.433708</td>\n",
       "      <td>0.885427</td>\n",
       "      <td>0.885427</td>\n",
       "      <td>0.828941</td>\n",
       "      <td>0.885427</td>\n",
       "      <td>0.817215</td>\n",
       "      <td>0.885427</td>\n",
       "      <td>0.816699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.236700</td>\n",
       "      <td>0.444661</td>\n",
       "      <td>0.894472</td>\n",
       "      <td>0.894472</td>\n",
       "      <td>0.844648</td>\n",
       "      <td>0.894472</td>\n",
       "      <td>0.814421</td>\n",
       "      <td>0.894472</td>\n",
       "      <td>0.822405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.236700</td>\n",
       "      <td>0.436374</td>\n",
       "      <td>0.886432</td>\n",
       "      <td>0.886432</td>\n",
       "      <td>0.825164</td>\n",
       "      <td>0.886432</td>\n",
       "      <td>0.825900</td>\n",
       "      <td>0.886432</td>\n",
       "      <td>0.820473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to cmed-event/checkpoint-500\n",
      "Configuration saved in cmed-event/checkpoint-500/config.json\n",
      "Model weights saved in cmed-event/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-event/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in cmed-event/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to cmed-event/checkpoint-1000\n",
      "Configuration saved in cmed-event/checkpoint-1000/config.json\n",
      "Model weights saved in cmed-event/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-event/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in cmed-event/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to cmed-event/checkpoint-1500\n",
      "Configuration saved in cmed-event/checkpoint-1500/config.json\n",
      "Model weights saved in cmed-event/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-event/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in cmed-event/checkpoint-1500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to cmed-event/checkpoint-2000\n",
      "Configuration saved in cmed-event/checkpoint-2000/config.json\n",
      "Model weights saved in cmed-event/checkpoint-2000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in cmed-event/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in cmed-event/checkpoint-2000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to cmed-event/checkpoint-2500\n",
      "Configuration saved in cmed-event/checkpoint-2500/config.json\n",
      "Model weights saved in cmed-event/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-event/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in cmed-event/checkpoint-2500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to cmed-event/checkpoint-3000\n",
      "Configuration saved in cmed-event/checkpoint-3000/config.json\n",
      "Model weights saved in cmed-event/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-event/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in cmed-event/checkpoint-3000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, event_tags.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 173\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_model(\"event\", model_checkpoints[model_type], epochs=50, classification=\"token\", chunk_by=\"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a92ab167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning data preprocessing\n",
      "Processed data written to event_sentence_train_for_sequence_classification.json and event_sentence_dev_for_sequence_classification.json\n",
      "Train label distribution:\n",
      "NoDisposition: 4509\n",
      "Disposition: 1118\n",
      "Undetermined: 455\n",
      "Dev label distribution:\n",
      "NoDisposition: 723\n",
      "Disposition: 199\n",
      "Undetermined: 84\n",
      "Loading dataset into huggingface format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-fdf3018be6186cdd\n",
      "Reusing dataset json (/home/brentdevries/.cache/huggingface/datasets/json/default-fdf3018be6186cdd/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0855f9f6e4b48fe97c6003d80844576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets using BERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/brentdevries/.cache/huggingface/datasets/json/default-fdf3018be6186cdd/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-b9d8308f020bd986.arrow\n",
      "Loading cached processed dataset at /home/brentdevries/.cache/huggingface/datasets/json/default-fdf3018be6186cdd/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-26b78d8f4c193bd1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BERT sequence classification model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running training *****\n",
      "  Num examples = 6082\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model sent to cuda\n",
      "Setting up training configuration\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1140' max='1140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1140/1140 23:31, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.632744</td>\n",
       "      <td>0.769384</td>\n",
       "      <td>0.769384</td>\n",
       "      <td>0.474574</td>\n",
       "      <td>0.769384</td>\n",
       "      <td>0.579008</td>\n",
       "      <td>0.769384</td>\n",
       "      <td>0.504495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.876200</td>\n",
       "      <td>0.510314</td>\n",
       "      <td>0.847913</td>\n",
       "      <td>0.847913</td>\n",
       "      <td>0.747337</td>\n",
       "      <td>0.847913</td>\n",
       "      <td>0.692860</td>\n",
       "      <td>0.847913</td>\n",
       "      <td>0.706320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.518900</td>\n",
       "      <td>0.468200</td>\n",
       "      <td>0.853877</td>\n",
       "      <td>0.853877</td>\n",
       "      <td>0.753246</td>\n",
       "      <td>0.853877</td>\n",
       "      <td>0.721391</td>\n",
       "      <td>0.853877</td>\n",
       "      <td>0.732058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1006\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to cmed-event/checkpoint-500\n",
      "Configuration saved in cmed-event/checkpoint-500/config.json\n",
      "Model weights saved in cmed-event/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-event/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in cmed-event/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1006\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to cmed-event/checkpoint-1000\n",
      "Configuration saved in cmed-event/checkpoint-1000/config.json\n",
      "Model weights saved in cmed-event/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-event/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in cmed-event/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1006\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1006\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='126' max='126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [126/126 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_model(\"event\", model_checkpoints[model_type], epochs=3, lr=5e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
