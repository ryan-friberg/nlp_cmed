{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8b15153-ad8e-4935-b550-70ee92bc522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import spacy\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "438e9be2-4d73-48e8-9f66-e11bd0f391e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x7fb95b2740a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disable = ['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer', 'parser', 'ner']\n",
    "nlp = spacy.load(\"en_core_sci_sm\", disable=disable)\n",
    "nlp.add_pipe(\"sentencizer\") # use senter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1582e8d8-857a-40f3-a0ed-9064342b401a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 350\n",
      "Dev samples: 50\n"
     ]
    }
   ],
   "source": [
    "# paths to data directories\n",
    "data_path = Path(\"n2c2Track1TrainingData/data\")\n",
    "train_path = data_path / \"train\"\n",
    "dev_path = data_path / \"dev\"\n",
    "\n",
    "# paths to data and annotation files\n",
    "train_data_files = sorted(list(train_path.rglob(\"*.txt\")), key=lambda x: x.name)\n",
    "train_ann_files = sorted(list(train_path.rglob(\"*.json\")), key=lambda x: x.name)\n",
    "dev_data_files = sorted(list(dev_path.rglob(\"*.txt\")), key=lambda x: x.name)\n",
    "dev_ann_files = sorted(list(dev_path.rglob(\"*.json\")), key=lambda x: x.name)\n",
    "\n",
    "assert(len(train_data_files) == len(train_ann_files))\n",
    "assert(len(dev_data_files) == len(dev_ann_files))\n",
    "\n",
    "print(f\"Training samples: {len(train_data_files)}\")\n",
    "print(f\"Dev samples: {len(dev_data_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "204c9602-e781-4c61-9d7f-9cbed6bfeed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_counts = {\n",
    "    \"num_medications\": 0,\n",
    "    \"event\": {\"Disposition\": 0, \"NoDisposition\": 0, \"Undetermined\": 0},\n",
    "    \"action\": {\"Start\": 0, \"Stop\": 0, \"Increase\": 0, \"Decrease\": 0, \"UniqueDose\": 0, \"OtherChange\": 0, \"Unknown\": 0},\n",
    "    \"temporality\": {\"Past\": 0, \"Present\": 0, \"Future\": 0, \"Unknown\": 0},\n",
    "    \"certainity\": {\"Certain\": 0, \"Hypothetical\": 0, \"Conditional\": 0, \"Unknown\": 0},\n",
    "    \"actor\": {\"Physician\": 0, \"Patient\": 0, \"Unknown\": 0}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6db50c6-8217-46de-b06d-5b453752c7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6188\n",
      "{'Disposition': 1183, 'NoDisposition': 4535, 'Undetermined': 470}\n",
      "{'Start': 466, 'Stop': 280, 'Increase': 103, 'Decrease': 41, 'UniqueDose': 263, 'OtherChange': 0, 'Unknown': 0}\n",
      "{'Past': 605, 'Present': 440, 'Future': 112, 'Unknown': 0}\n",
      "{'Certain': 993, 'Hypothetical': 105, 'Conditional': 83, 'Unknown': 0}\n",
      "{'Physician': 1077, 'Patient': 88, 'Unknown': 0}\n"
     ]
    }
   ],
   "source": [
    "for train_ann_path in train_ann_files:\n",
    "    anns = json.loads(train_ann_path.read_text())\n",
    "    for ann in anns:\n",
    "        train_label_counts[\"num_medications\"] += 1\n",
    "        for task in train_label_counts:\n",
    "            if task == \"num_medications\":\n",
    "                continue\n",
    "            \n",
    "            if task in ann:\n",
    "                if ann[task] in train_label_counts[task]:\n",
    "                    train_label_counts[task][ann[task]] += 1\n",
    "\n",
    "for task in train_label_counts:\n",
    "    print(train_label_counts[task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59ed35e8-609b-4852-ba1d-10d804082385",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_label_counts = {\n",
    "    \"num_medications\": 0,\n",
    "    \"event\": {\"Disposition\": 0, \"NoDisposition\": 0, \"Undetermined\": 0},\n",
    "    \"action\": {\"Start\": 0, \"Stop\": 0, \"Increase\": 0, \"Decrease\": 0, \"UniqueDose\": 0, \"OtherChange\": 0, \"Unknown\": 0},\n",
    "    \"temporality\": {\"Past\": 0, \"Present\": 0, \"Future\": 0, \"Unknown\": 0},\n",
    "    \"certainity\": {\"Certain\": 0, \"Hypothetical\": 0, \"Conditional\": 0, \"Unknown\": 0},\n",
    "    \"actor\": {\"Physician\": 0, \"Patient\": 0, \"Unknown\": 0}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42066975-5830-4ccb-8158-3bde8b4db9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031\n",
      "{'Disposition': 219, 'NoDisposition': 725, 'Undetermined': 87}\n",
      "{'Start': 95, 'Stop': 60, 'Increase': 23, 'Decrease': 13, 'UniqueDose': 22, 'OtherChange': 0, 'Unknown': 0}\n",
      "{'Past': 129, 'Present': 54, 'Future': 33, 'Unknown': 0}\n",
      "{'Certain': 173, 'Hypothetical': 29, 'Conditional': 17, 'Unknown': 0}\n",
      "{'Physician': 192, 'Patient': 17, 'Unknown': 0}\n"
     ]
    }
   ],
   "source": [
    "for dev_ann_path in dev_ann_files:\n",
    "    anns = json.loads(dev_ann_path.read_text())\n",
    "    for ann in anns:\n",
    "        dev_label_counts[\"num_medications\"] += 1\n",
    "        for task in dev_label_counts:\n",
    "            if task == \"num_medications\":\n",
    "                continue\n",
    "            \n",
    "            if task in ann:\n",
    "                if ann[task] in dev_label_counts[task]:\n",
    "                    dev_label_counts[task][ann[task]] += 1\n",
    "\n",
    "for task in dev_label_counts:\n",
    "    print(dev_label_counts[task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93c3fa78-a4cd-4efb-b278-6ca648f35655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 314674\n",
      "Training types: 23275\n",
      "Training sentences: 15228\n"
     ]
    }
   ],
   "source": [
    "num_tokens = 0\n",
    "num_sents = 0\n",
    "counter = Counter()\n",
    "for train_data_path in train_data_files:\n",
    "    text = train_data_path.read_text()\n",
    "    doc = nlp(text)\n",
    "    num_tokens += len(doc)\n",
    "    num_sents += len(list(doc.sents))\n",
    "    words = [token.text for token in doc]\n",
    "    counter.update(words)\n",
    "\n",
    "print(f\"Training tokens: {num_tokens}\")\n",
    "print(f\"Training types: {len(counter)}\")\n",
    "print(f\"Training sentences: {num_sents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f85b12a7-a264-4d46-b089-56c50d27eb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev tokens: 48987\n",
      "Dev types: 8224\n",
      "Dev sentences: 2574\n"
     ]
    }
   ],
   "source": [
    "num_tokens = 0\n",
    "num_sents = 0\n",
    "counter = Counter()\n",
    "for dev_data_path in dev_data_files:\n",
    "    text = dev_data_path.read_text()\n",
    "    doc = nlp(text)\n",
    "    num_tokens += len(doc)\n",
    "    num_sents += len(list(doc.sents))\n",
    "    words = [token.text for token in doc]\n",
    "    counter.update(words)\n",
    "\n",
    "print(f\"Dev tokens: {num_tokens}\")\n",
    "print(f\"Dev types: {len(counter)}\")\n",
    "print(f\"Dev sentences: {num_sents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83983369-8090-4ae0-bda7-96df10519d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpfinalenv",
   "language": "python",
   "name": "nlpfinalenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
