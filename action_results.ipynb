{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7243dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_model\n",
    "from run_model import run_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee2f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"domain\" # choose checkpoint type\n",
    "model_checkpoints = {\n",
    "    \"fast\": \"distilbert-base-uncased\",\n",
    "    \"base\": \"bert-base-uncased\",\n",
    "    \"domain\": \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f86c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning data preprocessing\n",
      "Processed data written to action_tokens200_train_for_token_classification.json and action_tokens200_dev_for_token_classification.json\n",
      "Train label distribution:\n",
      "Start: 436\n",
      "Stop: 270\n",
      "Increase: 97\n",
      "Decrease: 31\n",
      "UniqueDose: 258\n",
      "Dev label distribution:\n",
      "Start: 83\n",
      "Stop: 56\n",
      "Increase: 23\n",
      "Decrease: 9\n",
      "UniqueDose: 22\n",
      "Loading dataset into huggingface format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-db6a79ba2186e73f\n",
      "Reusing dataset json (/home/brentdevries/.cache/huggingface/datasets/json/default-db6a79ba2186e73f/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51d9db72ac34959883aed9e51c61f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets using BERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/brentdevries/.cache/huggingface/datasets/json/default-db6a79ba2186e73f/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-080d9b5ebece3a56.arrow\n",
      "Loading cached processed dataset at /home/brentdevries/.cache/huggingface/datasets/json/default-db6a79ba2186e73f/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-60f549ef9e504263.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BERT token classification model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running training *****\n",
      "  Num examples = 537\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 3400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model sent to cuda\n",
      "Setting up training configuration\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3400' max='3400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3400/3400 57:49, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.613525</td>\n",
       "      <td>0.255208</td>\n",
       "      <td>0.255208</td>\n",
       "      <td>0.225933</td>\n",
       "      <td>0.255208</td>\n",
       "      <td>0.255310</td>\n",
       "      <td>0.255208</td>\n",
       "      <td>0.214831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.610692</td>\n",
       "      <td>0.255208</td>\n",
       "      <td>0.255208</td>\n",
       "      <td>0.225413</td>\n",
       "      <td>0.255208</td>\n",
       "      <td>0.255310</td>\n",
       "      <td>0.255208</td>\n",
       "      <td>0.215600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.606311</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.230244</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.262539</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.224659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.600405</td>\n",
       "      <td>0.276042</td>\n",
       "      <td>0.276042</td>\n",
       "      <td>0.230878</td>\n",
       "      <td>0.276042</td>\n",
       "      <td>0.258663</td>\n",
       "      <td>0.276042</td>\n",
       "      <td>0.226288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.593216</td>\n",
       "      <td>0.260417</td>\n",
       "      <td>0.260417</td>\n",
       "      <td>0.216848</td>\n",
       "      <td>0.260417</td>\n",
       "      <td>0.232576</td>\n",
       "      <td>0.260417</td>\n",
       "      <td>0.212445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.585154</td>\n",
       "      <td>0.255208</td>\n",
       "      <td>0.255208</td>\n",
       "      <td>0.209672</td>\n",
       "      <td>0.255208</td>\n",
       "      <td>0.223880</td>\n",
       "      <td>0.255208</td>\n",
       "      <td>0.206927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.575036</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.222250</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.235929</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.222465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.564643</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.179075</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.192439</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.180773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.554372</td>\n",
       "      <td>0.286458</td>\n",
       "      <td>0.286458</td>\n",
       "      <td>0.189255</td>\n",
       "      <td>0.286458</td>\n",
       "      <td>0.199668</td>\n",
       "      <td>0.286458</td>\n",
       "      <td>0.189247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.543692</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.178391</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.186460</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.177014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.533033</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>0.161875</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>0.188390</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>0.170044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.522184</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.174077</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.200482</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.181508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.510768</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.175319</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.204118</td>\n",
       "      <td>0.348958</td>\n",
       "      <td>0.184981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.501928</td>\n",
       "      <td>0.364583</td>\n",
       "      <td>0.364583</td>\n",
       "      <td>0.178578</td>\n",
       "      <td>0.364583</td>\n",
       "      <td>0.210120</td>\n",
       "      <td>0.364583</td>\n",
       "      <td>0.187964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.492350</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.195745</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.224578</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.199690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.484822</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.191124</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.220942</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.195221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.475382</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.187324</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.218488</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.190670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.470275</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.184643</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.217262</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.187663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.463515</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.190719</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.219671</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.189835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.460290</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>0.179422</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>0.212442</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>0.183362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.454042</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.187666</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.217262</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.188092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.451673</td>\n",
       "      <td>0.369792</td>\n",
       "      <td>0.369792</td>\n",
       "      <td>0.168921</td>\n",
       "      <td>0.369792</td>\n",
       "      <td>0.205170</td>\n",
       "      <td>0.369792</td>\n",
       "      <td>0.172953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.445844</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.186095</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.219715</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.186851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.444566</td>\n",
       "      <td>0.369792</td>\n",
       "      <td>0.369792</td>\n",
       "      <td>0.180212</td>\n",
       "      <td>0.369792</td>\n",
       "      <td>0.225214</td>\n",
       "      <td>0.369792</td>\n",
       "      <td>0.190607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.436369</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.192455</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.228850</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.198587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.435511</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.194280</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.252442</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.207729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.431392</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>0.186786</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>0.247623</td>\n",
       "      <td>0.380208</td>\n",
       "      <td>0.201237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.426035</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.193036</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.256714</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.208644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.576600</td>\n",
       "      <td>1.418331</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.195117</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.256714</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.211025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.412475</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.203202</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.268215</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>0.220503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.401636</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.201876</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.272486</td>\n",
       "      <td>0.390625</td>\n",
       "      <td>0.223821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.393530</td>\n",
       "      <td>0.401042</td>\n",
       "      <td>0.401042</td>\n",
       "      <td>0.217037</td>\n",
       "      <td>0.401042</td>\n",
       "      <td>0.279759</td>\n",
       "      <td>0.401042</td>\n",
       "      <td>0.235690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.384269</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.233374</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.296123</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.251663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.371476</td>\n",
       "      <td>0.432292</td>\n",
       "      <td>0.432292</td>\n",
       "      <td>0.244065</td>\n",
       "      <td>0.432292</td>\n",
       "      <td>0.303352</td>\n",
       "      <td>0.432292</td>\n",
       "      <td>0.260285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.360963</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.242560</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.315531</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.263195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.347664</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.251332</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.320350</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.270018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.332670</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.443434</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.321817</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.283271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.322064</td>\n",
       "      <td>0.432292</td>\n",
       "      <td>0.432292</td>\n",
       "      <td>0.445249</td>\n",
       "      <td>0.432292</td>\n",
       "      <td>0.324227</td>\n",
       "      <td>0.432292</td>\n",
       "      <td>0.281866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.303758</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.454674</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.334545</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.295229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.286581</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.459226</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.345650</td>\n",
       "      <td>0.447917</td>\n",
       "      <td>0.312994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.276736</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.405077</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.349570</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.323694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.262138</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.385878</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.369371</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.347941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.244647</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.390257</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.373007</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.352230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.407700</td>\n",
       "      <td>1.222953</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.405293</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.393751</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.375456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>1.219381</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.403584</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.391341</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>0.373456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>1.198908</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.414118</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.416202</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.397943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>1.169724</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.424716</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.418655</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.404635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>1.156055</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.417087</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.447591</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.421365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>1.121731</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.430671</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.461106</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.436785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>1.124657</td>\n",
       "      <td>0.536458</td>\n",
       "      <td>0.536458</td>\n",
       "      <td>0.427578</td>\n",
       "      <td>0.536458</td>\n",
       "      <td>0.461062</td>\n",
       "      <td>0.536458</td>\n",
       "      <td>0.425342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>1.090764</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.438426</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.472059</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.445417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>1.070010</td>\n",
       "      <td>0.567708</td>\n",
       "      <td>0.567708</td>\n",
       "      <td>0.455071</td>\n",
       "      <td>0.567708</td>\n",
       "      <td>0.500511</td>\n",
       "      <td>0.567708</td>\n",
       "      <td>0.467368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>1.048173</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.466637</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.506557</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.475969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>1.018518</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.488992</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.512363</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.490306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>0.996584</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.480655</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.518649</td>\n",
       "      <td>0.598958</td>\n",
       "      <td>0.489062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>0.980673</td>\n",
       "      <td>0.588542</td>\n",
       "      <td>0.588542</td>\n",
       "      <td>0.471772</td>\n",
       "      <td>0.588542</td>\n",
       "      <td>0.513830</td>\n",
       "      <td>0.588542</td>\n",
       "      <td>0.478493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>0.943037</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>0.526732</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>0.548879</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>0.528788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.195500</td>\n",
       "      <td>0.962532</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.516454</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.538210</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.506407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.922525</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.520786</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.552756</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.524372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.888314</td>\n",
       "      <td>0.661458</td>\n",
       "      <td>0.661458</td>\n",
       "      <td>0.523132</td>\n",
       "      <td>0.661458</td>\n",
       "      <td>0.563665</td>\n",
       "      <td>0.661458</td>\n",
       "      <td>0.534555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.861773</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.534558</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.578407</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.549705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.872457</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.541880</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.573544</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.546786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.840485</td>\n",
       "      <td>0.692708</td>\n",
       "      <td>0.692708</td>\n",
       "      <td>0.555533</td>\n",
       "      <td>0.692708</td>\n",
       "      <td>0.579349</td>\n",
       "      <td>0.692708</td>\n",
       "      <td>0.559911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.830985</td>\n",
       "      <td>0.692708</td>\n",
       "      <td>0.692708</td>\n",
       "      <td>0.552921</td>\n",
       "      <td>0.692708</td>\n",
       "      <td>0.585636</td>\n",
       "      <td>0.692708</td>\n",
       "      <td>0.559369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.831214</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.558253</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.586622</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.564488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>0.713542</td>\n",
       "      <td>0.713542</td>\n",
       "      <td>0.562018</td>\n",
       "      <td>0.713542</td>\n",
       "      <td>0.598954</td>\n",
       "      <td>0.713542</td>\n",
       "      <td>0.573622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.804953</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.557885</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.597531</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.573158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.814529</td>\n",
       "      <td>0.723958</td>\n",
       "      <td>0.723958</td>\n",
       "      <td>0.573587</td>\n",
       "      <td>0.723958</td>\n",
       "      <td>0.610455</td>\n",
       "      <td>0.723958</td>\n",
       "      <td>0.583034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.790634</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.564702</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.611485</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.583565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.800756</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.582092</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.596940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.818271</td>\n",
       "      <td>0.723958</td>\n",
       "      <td>0.723958</td>\n",
       "      <td>0.574859</td>\n",
       "      <td>0.723958</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.723958</td>\n",
       "      <td>0.580083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.822959</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.582794</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.620137</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.593023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.808710</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.581384</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.628637</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.598549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.849534</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.582794</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.620137</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.593023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.843925</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.585331</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.855438</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.582794</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.620137</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.593023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.857619</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.582794</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.620137</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.593023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.827403</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.578474</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.619941</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.593216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.875787</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.578977</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.615078</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.589378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.845567</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.582458</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.598959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.907020</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.577784</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.616501</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.587714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.883257</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.585356</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.615078</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.592944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.915227</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.577928</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.607805</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.584124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.930650</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.581968</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.615078</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.591102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.913018</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.592689</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.618714</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.599194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.958880</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.580984</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.621759</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.592540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.936195</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.601321</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.614683</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.602211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.961105</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.595998</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.927310</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.598021</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.615078</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.599620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.894417</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.606821</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.622351</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.608618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.919310</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.604810</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.618714</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.605246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.954074</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.607011</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.630060</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.612099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.937533</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.604810</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.618714</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.605246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.991585</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.604810</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.618714</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.605246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.968571</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.648387</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.647618</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.639487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>1.004083</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.608127</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.625395</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.609588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.987940</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.689426</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.677113</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.674637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>1.138768</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.651060</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.632437</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.629627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>1.141273</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.680962</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.662567</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.659749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>1.130878</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.680045</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.652250</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.654822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to cmed-action/checkpoint-500\n",
      "Configuration saved in cmed-action/checkpoint-500/config.json\n",
      "Model weights saved in cmed-action/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-action/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in cmed-action/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to cmed-action/checkpoint-1000\n",
      "Configuration saved in cmed-action/checkpoint-1000/config.json\n",
      "Model weights saved in cmed-action/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-action/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in cmed-action/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to cmed-action/checkpoint-1500\n",
      "Configuration saved in cmed-action/checkpoint-1500/config.json\n",
      "Model weights saved in cmed-action/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-action/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in cmed-action/checkpoint-1500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to cmed-action/checkpoint-2000\n",
      "Configuration saved in cmed-action/checkpoint-2000/config.json\n",
      "Model weights saved in cmed-action/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-action/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in cmed-action/checkpoint-2000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to cmed-action/checkpoint-2500\n",
      "Configuration saved in cmed-action/checkpoint-2500/config.json\n",
      "Model weights saved in cmed-action/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-action/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in cmed-action/checkpoint-2500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to cmed-action/checkpoint-3000\n",
      "Configuration saved in cmed-action/checkpoint-3000/config.json\n",
      "Model weights saved in cmed-action/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-action/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in cmed-action/checkpoint-3000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, action_tags.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 87\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11/11 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEKCAYAAAA/2c+EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA0R0lEQVR4nO3deZgU5bXH8e9vNvZ9YBwUxQXxoiIgiKhR3DXJDRr3mLjEG/VGSeKNSTSaiDHhmphVXIkxclXcogaTKGBARIzIvogGUWRRBmHY99nO/aPeYZphlh7oma6G83meeqa7uvqt0z0zp98+9dZbMjOcc87FT1a6A3DOOVczT9DOORdTnqCdcy6mPEE751xMeYJ2zrmY8gTtnHMx5QnaOedSTFJPSXMSlo2Sviepo6TXJS0KPzvU2Y6Pg3bOucYjKRv4DBgI3ASsNbN7Jd0GdDCzH9X2XO9BO+dc4zoT+NjMlgJDgFFh/SjggrqemNO4cTmA/I7Z1r1bbrrDSMqi99ukO4QGsfLydIfQMBn0hVXNm6U7hKRtK91ASdlW7U0b557eytasTe7vaea8HQuA7QmrRprZyFo2vxx4JtwuMLMiADMrktSlrv14gm4C3bvlMm1ct3SHkZQv9j4z3SE0SMX6DekOoUGsrCzdISQtu/sR6Q4hae8seWKv2yheW8674w5Katvcwo+3m1n/+raTlAd8Bbh9T2LyBO2ccwAY5VaR6kbPB2aZ2efh/ueSCkPvuRBYVdeTvQbtnHNE1acKLKmlAa6gqrwB8Apwdbh9NTCmrid7D9o554IKUteDltQSOBu4IWH1vcDzkq4DlgGX1NWGJ2jnnAMMozSFJQ4z2wp0qrZuDdGojqR4gnbOOaISR3nMhtl4gnbOuaCB9eVG5wnaOecIPeiYnVntCdo554KUD7LbS56gnXOO6CCh16Cdcy6GzKA0XvnZE7RzzkVEOXs1nUfKeYJ2zjnCmYTeg3bOuXjyHrRzzsVQdKKKJ2jnnIsdA0otXvPHeYJ2zjnAEOUxm+DTE3QGWP5RM4bf2H3n/ZXL8vjGD1Zy1sVrGX5jdz7/NI+Cg0q449EltGkfvyuMZGUZf3hmOmtWNWPY0OPSHU6tbrlvCQPP3MD6NTncePbR6Q6nXv0Hb+TGe1aQnWW89kxHnn+gIN0h1emCixdx7pc+wUwsWdyW3/2yP6Wl2ekOaxcVFq8SR7w+LhqZpDskLZA0L1xpd2C40m7LPWjrGkldGyPO6rodsYOH/7mQh/+5kAfGLaRZiwpOPn89zz/Qhb6nbOLPb39A31M28dwDdV49J22GXLmc5Z+0SncY9Xr9hU7ceVWPdIeRlKws46bhn3HnlYfyrcE9OX3Ieg7usb3+J6ZJp/xtfOWrH/HdG87k2988m+xs47Qzlqc7rF1U1qCTWZrKfpOgJQ0Cvgz0M7PewFnAcuB7QIMSdLhK7zVAkyToRHPeakPhITsoOKiUd8a146xL1wJw1qVreWdsu6YOp16dCrYz4NQ1jHupMN2h1Ou9aW3YtD5ePbra9Oy7lRVL8li5rBllpVlMGtOeQefG+/Jf2dlGXrNysrIqaNasnDVrWqQ7pGpEuWUltTSV/SZBA4VAsZntADCzYuBioiT7hqQ3ACQ9LGlG6GnfXflkSUsk/VTSFKKrJPQHng498Sb7S5s0pj2DL1gPwLriXDoVRNe461RQxvo18atY3fDDRTz+28OpqIjXV8dM1+mAUlavyNt5v7gol/zC0jRGVLc1xS146fkejHruVZ5+8R9s2ZLL7BnxKslEV1TJSmppKvtTgh4PdJP0oaSHJJ1mZvcDK4DTzez0sN0d4WKQvYHTJPVOaGO7mZ1iZk8BM4ArzayPmW2rvjNJ14dEP2P1mtTUhUtLxNTx7Tj1P9enpL3GdsKpxaxfm8dHH7RNdyj7HNXweRezidh20bp1CSeeVMS1V5zP1y/+Es2bl3H6WcvSHdYuzESJZSe1NJX9JkGb2WbgeOB6YDXwnKRratj0UkmzgNnA0UCvhMeea8D+RppZfzPr37lTan6h0ye24Yhjt9Khc9Rr7pBfyprPo17zms9zaN8pXleM7tVnAycOLubPr/2LH/1qAb1PWMetwxekO6x9QnFRLp27luy8n19YypqVuWmMqG59jl/FypWt2LihGeXlWbz91oH8xzFr0h3WbipQUktTid934kZkZuXAJGCSpPlUXbwRAEmHArcCA8xsnaQngOYJm2xpolBrNOmvHXaWNwBOPGcj/3y+I5cNXcU/n+8YuxrkE/cfzhP3Hw7Asf3XcdHVy/j1j+M/OiITLJzTkgMPLaGg2w7WrMxl8JD13HvTIekOq1arV7XkqF5raNasjB07sunTbxWLFnZId1i7iA4SxqvPut8kaEk9gQozWxRW9QGWAt2BNkAx0JYoCW+QVEB0yfRJtTS5KTyvSWzfKma91Ybv/qrqyPdlN3/OL27szthnO9HlwGiYndtzt41YTO9Bm2jboYwn353HU7/tyrjn8tMdVo0qysWDdxzI8NGLycqG8c92ZOmHzet/Ypos/KAjU948iPtHTqC8PIvFi9rz2t8PTXdY1ahJDwAmY79J0EBrYISk9kAZ8BFRueMK4DVJRWZ2uqTZwAJgMfB2He09ATwiaRswqKY6dCo1b2n8ZcF7u6xr27GcXz7/cWPuNmXmz+jA/Bnx6jFVd+/Qw9IdQoNMn9iW6RMzp77/9BO9ePqJXvVvmCaVBwnjZL9J0GY2EziphodGhKVyu2tqeX73avdfBF5MXYTOuXQrj9mJKvtNgnbOuboYotRSlxLDt/XHgGOIOujfBBYSDTboDiwBLjWzdbW1Ea/+vHPOpUnlQcJkliT9ARhrZkcBxwEfALcBE8ysBzAh3K+VJ2jnnCNMlmTJLfWR1BY4FfgTgJmVmNl6YAgwKmw2CrigrnY8QTvnXNCAMwnzK09EC8v11Zo6jOh8iz9Lmi3pMUmtgAIzKwIIP+ucQMdr0M45R3QmZgOG2RWHM45rkwP0A4aa2buS/kA95YyaeA/aOeeoPEiYndSShE+BT83s3XD/L0QJ+3NJhQDh56q6GvEE7ZxzQaoOEprZSmB5OEEO4EzgfeAVqs5gvhoYU1c7XuJwzjmiHnSKJ+wfSjTjZR7RiW/XEnWKn5d0HbAMuKSuBjxBO+dckMq5OMxsDtG0xNWdmWwbnqCdc45wqrfPxeGcc3HUtJezSoYnaOecI+pBJzlCo8l4gnbOOaIrqniJwznnYsrng3bOuRiK5oP2GrRzzsWQX1Flv7RwaT6D/+tb6Q4jKcvviNdBkvocccvUdIfQINltM+cKKBUfL0l3CEmzsh173wak+kSVveYJ2jnnqJqLI048QTvnXODXJHTOuRiKphv1EodzzsWS16Cdcy6GotnsvMThnHOxE53q7QnaOediyHvQzjkXW34moXPOxZCP4nDOuRjzEodzzsVQI1yTcK95gnbOOaJRHGXeg3bOuXjyEodzzsWReYnDOediKdUT9ktaAmwCyoEyM+svqSPwHNAdWAJcambramsjXv1555xLo4rQi65vaYDTzayPmfUP928DJphZD2BCuF8r70FngB9eM5lBvZexflMLrr3rop3rLzxjARee8T7l5WLq/G48+peBaYwyotIKDnxgASozKDe2HNeRted3o+PY5bSduoryVrkArPlSN7b26pDmaHfXf/BGbrxnBdlZxmvPdOT5BwrSHVKtcvMq+NVTc8nNM7KzjSnj83l6xCHpDqtGt9y3hIFnbmD9mhxuPPvodIdToyaasH8IMDjcHgVMAn5U28b7ZYKWdAfwNaKvHhXADcAgYKSZbU1nbDUZ+3YPXp7Yix9f9+bOdX16ruCUPku5bthXKS3Lpn2bbWmMsIrliM++3Qtrlg3lFRx0/wK2/Ed7ANafVsj607umN8A6ZGUZNw3/jNsvP4ziolxGvLqIqePasWxR83SHVqPSEnH7Nb3ZvjWb7JwKfv30PGZM7sDCufG7asvrL3Tib6O6cOvvPkl3KLUyRFlF0kWFfEkzEu6PNLORuzUJ4yUZ8Gh4vMDMigDMrEhSl7p2st8laEmDgC8D/cxsh6R8II+oLvQUELsEPW9RIQd02rTLuiGDP2D0a8dRWhZdAWL9phbpCG13UpScAZVHveiYnT1bq559t7JiSR4rlzUDYNKY9gw6d0NsEzSI7Vuj9zonx8jOqYhSQgy9N60NBQft/WWpGlsDatDFCWWL2pxsZitCEn5d0r8bGs9+l6CBQqI3dweAmRVL+g7QFXhDUrGZnS7pCuDHROnlH2b2IwBJm4FHgdOBdcDlZra6qV9Et4INHNtjJdddOIOS0mwefmEgC5d0buowalZhdPvNfHKLt7PhlAJ2HNKGVh+sp91bK2kzvZgd3VpRPOQQKlrG68+v0wGlrF6Rt/N+cVEuR/WL3ef1LrKyjD+8OJuuB2/j76O7snBe/HrPGcNSW+IwsxXh5ypJLwMnAJ9LKgy950JgVV1t7I8HCccD3SR9KOkhSaeZ2f3ACqKC/umSugK/BM4A+gADJF0Qnt8KmGVm/YA3gbua/BUA2dlGm1Y7+Pbwr/DIX05g2A0TiE33KUss/0FvlgzrR7NlW8gr2sqGkwtYemdflt96LGVtc8kfszTdUe5GNfxvWkze0tpUVIihF/bjqsEDObL3Jg7psSXdIWWsyhp0Kg4SSmolqU3lbeAc4D3gFeDqsNnVwJi62tnvErSZbQaOB64HVgPPSbqm2mYDgElmttrMyoCngVPDYxVE5RCISiKn1LQfSddLmiFpRmlJ6v9pVq9rxVuzugPi3590ocJEu9bbU76fvVHRIodth7el5b/XU94mD7IEWWLjoC40W7Y53eHtprgol85dS3bezy8sZc3K3DRGlLwtm3KYP60dx3+h1hFbLgkpHMVRAEyRNBeYRvQtfCxwL3C2pEXA2eF+rfa7BA1gZuVmNsnM7gJuBi6qtklDvufU2Mcys5Fm1t/M+ufmtdrTUGs1ZfYh9D2qCICDCjaQm1PBhs3pr5VmbS4la1sZACqpoOWHGyjp0oLsDVWJr9W8dZQUtkxXiLVaOKclBx5aQkG3HeTkVjB4yHqmjm+X7rBq1bZDCa3aRO91XrNy+gxaz6eLY3IsIgMZorwiK6ml3rbMFpvZcWE52sx+EdavMbMzzaxH+Lm2rnbiVQRsApJ6AhVmtiis6gMsJRo43gYoBt4F/hAOIK4DrgBGhO2zgIuBZ4lGgkxp7Jh/8q2J9OlZRLvW23nhV6P58yvH8+qUI/nRtZP5890vUlqWxf8+fhpxOBqXs7GEgtEfR98zzNjcpxNbj+5Al6c+otmKLYAo69iMVZccmu5Qd1NRLh6840CGj15MVjaMf7YjSz9M/4debTp2LuX79y4kK9uQ4K2x+Uyb1CndYdXothGL6T1oE207lPHku/N46rddGfdcfrrD2k3c5oOWxb3IlmKSjidKtu2BMuAjonLHFcBNQFGoQ38NuJ0o671qZj8Mz98M/A74IrABuKy+g4Rt2h9kfU/5TuO8oBRbfnZ2ukNokCNumZruEBoku23mHMSr2BrvA6SJppaNY2PF2r3Krq2PPMD6PHRVUtu+ffZ9M5MYxbHX9rsetJnNBE6q4aERVPWSMbPRwOha2vgJ8JNGCdA5lzbmc3E451wc+WRJGc/MWqc7Budc4/AetHPOxZAZlFd4gnbOuViK2ygOT9DOOUd0QoOXOJxzLpb8IKFzzsVW3E4L8QTtnHOBlziccy6GolEc8ZqeyBO0c84FXuJwzrmY8hKHc87FkCFP0M45F1cxq3B4gnbOOQAMzE/1ds65ePISh3POxVTGjOKQNII6SjJmlhmXCImBrK0ltJq9PN1hJOWIV1emO4QG2fHFAekOoUGaj5+d7hBcLTJtLo4ZTRaFc86lmwGZkqDNbFTifUmtzGxL44fknHPpEbcSR73nNUoaJOl94INw/zhJDzV6ZM4516SEVSS3JNWalC1ptqS/h/sdJb0uaVH42aG+NpI58fz3wLnAGgAzmwucmlSEzjmXSSzJJTnfJXRsg9uACWbWA5gQ7tcpqZlBzKz6Ea7yZCN0zrmMYNFBwmSW+kg6CPgS8FjC6iFAZel4FHBBfe0kM8xuuaSTAJOUB3yHXT8VnHNu35C6GvTvgR8CbRLWFZhZEYCZFUnqUl8jyfSgbwRuAg4EPgP6hPvOObePUZIL+ZJmJCzX72xB+jKwysxm7m009fagzawYuHJvd+Scc7FXkfSWxWbWv5bHTga+IumLQHOgraSngM8lFYbecyGwqr6dJDOK4zBJf5O0WtIqSWMkHZb0y3DOuUxQOQ46maWuZsxuN7ODzKw7cDkw0cy+DrwCXB02uxoYU19IyZQ4RgPPA4VAV+AF4JkknueccxnFLLllD90LnC1pEXB2uF+nZA4SysyeTLj/lKSb9zBA55yLrxSfqGJmk4BJ4fYa4MyGPL+uuTg6hptvSLoNeJYo/MuAf+xBrM45F2+Zcqo3MJMoIVdGfEPCYwbc01hBOedcOihmp3rXNRfHoU0ZiHPOpZUJMnHCfknHAL2IhowAYGb/11hBOedcWmRKD7qSpLuAwUQJ+lXgfGAK4AnaObdviVmCTmaY3cVERx5Xmtm1wHFAs0aNyjnn0iG1kyXttWRKHNvMrEJSmaS2RGe/+IkqafT4395k29YcKspFebn43jcGpTukWvUfvJEb71lBdpbx2jMdef6BgnSHtIsfXjOZQb2XsX5TC66966Kd6y88YwEXnvE+5eVi6vxuPPqXgWmMsma33LeEgWduYP2aHG48++h0h1OnjIg1kybsTzBDUnvgj0QjOzYD0xozqOokbTaz1k25z7i7/YYBbFyfl+4w6pSVZdw0/DNuv/wwiotyGfHqIqaOa8eyRc3rf3ITGft2D16e2IsfX/fmznV9eq7glD5LuW7YVykty6Z9m21pjLB2r7/Qib+N6sKtv/sk3aHUK1NizZhRHJXM7Nvh5iOSxgJtzWxe44aVepJyzKws3XHsT3r23cqKJXmsXBZVxCaNac+gczfEKkHPW1TIAZ027bJuyOAPGP3acZSWZQOwflOLdIRWr/emtaHgoB3pDiMpGRNrpiRoSf3qeszMZjVOSLWTNBgYBhQDxxD16L9uZiZpAPAHoBWwg6hufhHRnKzNgVaS/hMYARxL9NqHmdkYSd2BJ8NzAW42s3+FCU2eA9qG7f/bzN6SdA5wN1Et/mPgWjPb3LivvoqZuOfBGWDitRcPYuzL3Zpq1w3S6YBSVq+o6uUXF+VyVL+taYwoOd0KNnBsj5Vcd+EMSkqzefiFgSxc0jndYbkmkEk96N/U8ZgBZ6Q4lmT1BY4GVgBvAydLmkaUSC8zs+mhVl75vXQQ0NvM1koaTjRxyTdD2WaapH8S1dXPNrPtknoQzTXSH/gaMM7MfiEpG2gpKR+4EzjLzLZI+hHwP8DPEoMM0w9eD9A8O7XVmR988wTWFjenXYcd/PyhGSxf0ooFszvW/8QmphrKeXG75ltNsrONNq128O3hX+GoQ1cz7IYJXHH7ZVSds+X2WZlSgzaz05sykAaYZmafAkiaA3QHNgBFZjYdwMw2hscBXjezteG55xBNA3hruN8cOJgo2T8gqQ/R1WKODI9PBx6XlAv81czmSDqNaMjh26H9POCd6kGa2UhgJEC7vC4pTUtri6MSwYZ1zXjnjQJ6HrMhlgm6uCiXzl1Ldt7PLyxlzcrcNEaUnNXrWvHWrO6A+PcnXagw0a71djZsjmepw6VIE4/QSEZSl7yKmcRCVjnRh4yo/a1NvBK5gIvMrE9YDjazD4BbgM+JhhD2J0q6mNlkousvfgY8Kemq0MbrCW30MrPrUvj66tSseRktWpbtvN3vxDUs/Siex08XzmnJgYeWUNBtBzm5FQwesp6p49ulO6x6TZl9CH2PKgLgoIIN5OZUsGFzfOrmrhFl4DC7TPBvoKukAaHE0YaqEkeiccBQSUND3bqvmc0G2gGfhuGEVwPZAJIOAT4zsz9KagX0A34BPCjpCDP7SFJL4CAz+7ApXmiHTiXc8evZQPRV/M2xhcx8J5710Ypy8eAdBzJ89GKysmH8sx1Z+mG8Et1PvjWRPj2LaNd6Oy/8ajR/fuV4Xp1yJD+6djJ/vvtFSsuy+N/HTyOO5Y3bRiym96BNtO1QxpPvzuOp33Zl3HP56Q6rRpkSq5KfsL9J7BMJ2sxKJF0GjJDUgig5n1XDpvcQXStsnqL6xBLgy8BDwIuSLgHeoKrXPRj4gaRSouGFV5nZaknXAM9Iqjxh506gSRL0ys9aMvSKk5tiVykxfWJbpk9sm+4wanXPH2s+lPKLx+Ja4aty79DMOR0hY2KNWYkjmVO9RXTJq8PM7GeSDgYOMLMmGwtdOQY6cW7VcP/mhNvTgROrPfWJsFRus41dZ+WrXL8I6J2w6vawfhRVV+FN3H4iMKCBL8M5F2Oy+I3iSKYG/RDRSIgrwv1NwIONFpFzzqVLCi55lUrJlDgGmlk/SbMBzGydpHifwuacc3siZj3oZBJ0aRgDbACSOtOQa98651yGiFuJI5kEfT/wMtBF0i+IZre7s1Gjcs65pmYZOIrDzJ6WNJPo1GkBF4Sxw845t2/JtB50GLWxFfhb4jozW9aYgTnnXJPLtARNdAXvyovHNgcOBRYSzYfhnHP7jFTVoCU1ByYTTaiWA/zFzO6S1JFo3qDuROdhXGpm62prp95hdmZ2rJn1Dj97ACcQXfLKOedczXYAZ5jZcUAf4DxJJwK3ARNCLp0Q7teqwXNxhGlG/SQN59y+J0VzcVikcgri3LAYMISqk99GARfU1U4yNej/SbibRTQfxer6Q3TOuQyS4lEcYXjyTOAI4EEze1dSgZkVAZhZkaQudbWRTA26TcLtMqKa9It7GLNzzsVX8jXofEkzEu6PDFMMVzVlVg70CXPPvyzpmIaGU2eCDp8Arc3sBw1t2DnnMolo0EHCYjPrn8yGZrZe0iTgPOBzSYWh91xIdLGQWtVagw7X8CsnKmk459y+L0U1aEmdQ8+ZMMPmWUTTIr8CXB02uxoYU1c7dfWgpxEl5zmSXgFeIGHyezN7qf4wnXMuQ6R2NrtCYFSoQmQBz5vZ3yW9Azwv6TpgGXBJXY0kU4PuCKwhugZh5XhoAzxBO+f2LSk6SGhm84iun1p9/Rqis7KTUleC7hJGcLxHVWLeuZ9kd+Ccc5kikyZLygZaU/O1fmL2MmLODCstTXcU+6SWUxamO4QGsbzMmam3YuvWdIeQvFRlpJhltroSdJGZ/azJInHOuXSK4VW960rQ8btKpnPONaJMKnEkXch2zrl9QqYkaDNb25SBOOdcumXchP3OObdfyLAatHPO7TdE/A68eYJ2zrlK3oN2zrl4yqRRHM45t3/xBO2cczGU4gn7U8ETtHPOVfIetHPOxZPXoJ1zLq48QTvnXDx5D9o55+LISNmE/aniCdo552jwRWObhCfoDJWVZfzhmemsWdWMYUOPS3c4teo/eCM33rOC7CzjtWc68vwDBekOqVa5eRX86qm55OYZ2dnGlPH5PD3ikHSHVav8wh3cet9HdMgvxQxee7aAMaMK0x1WrTLib8ETdN0klQPzgVygDBgF/N7MYvblI72GXLmc5Z+0omWrsnSHUqusLOOm4Z9x++WHUVyUy4hXFzF1XDuWLWqe7tBqVFoibr+mN9u3ZpOdU8Gvn57HjMkdWDi3bbpDq1F5mfjj/x7Cxwta06JVOff/dR6z327Hso9apju03WTK34IsXhk6K90B1GCbmfUxs6OBs4EvAnftbaOSYvdhtKc6FWxnwKlrGPdSfHtLAD37bmXFkjxWLmtGWWkWk8a0Z9C5G9IdVh3E9q3ZAOTkGNk5FbHrUSVatzqPjxe0BmDblmyWf9yCTgUlaY6qZhnxt2ANWJpIHBP0Tma2CrgeuFmRbEn3SZouaZ6kGyq3lfRDSfMlzZV0b1g3SdJwSW8C35V0vKQ3Jc2UNE5SYdjuW6HNuZJelNQyrL9E0nth/eSwrtYYmsoNP1zE4789nIqKuM29tatOB5SyekXVNfiKi3LJL4z3tRmzsowRL89i9NtTmf2vDiycF8/ec3VdDtzO4b22sHBu63SHUqNM+VuQJbc0ldj3Ks1ssaQsoAswBNhgZgMkNQPeljQeOAq4ABhoZlsldUxoor2ZnSYpF3gTGGJmqyVdBvwC+Cbwkpn9EUDSz4HrgBHAT4FzzewzSe1De9fVFIOZfdK470TkhFOLWb82j48+aMux/dc1xS73mGr4/IjZN8jdVFSIoRf2o1WbMu584H0O6bGFpYtapTusOjVvWc6dD37Ioz/vztbN8fyXzpS/BT/Ve89U/nrPAXpLujjcbwf0AM4C/mxmW2G3q8E8F372BI4BXlf015INFIXHjgmJuT3RlczHhfVvA09Ieh54qZ4YdknQkq4n6v3TPCt1vZpefTZw4uBiBpyyhtxmFbRsVcatwxfw6x8fnbJ9pEpxUS6du1Z95c4vLGXNytw0RpS8LZtymD+tHcd/YV2sE3R2TgV3PriQN17J51/jO6U7nFplzN9Cij40JHUD/g84gGjw3kgz+0PoPD4HdAeWAJeaWa09rdgnaEmHAeXAKqJEPdTMxlXb5jxqf2u3VG4GLDCzQTVs8wRwgZnNlXQNMBjAzG6UNBD4EjBHUp/aYqjOzEYCIwHa5XZOWV/hifsP54n7Dwfg2P7ruOjqZbFMzgAL57TkwENLKOi2gzUrcxk8ZD333hTfURFtO5RQXpbFlk055DUrp8+g9fzlsYPSHVYdjO/978cs/6gFLz/eNd3B1Ckj/hZSW74oA75vZrMktQFmSnoduAaYYGb3SroNuA34UW2NxDpBS+oMPAI8YGYmaRzw35ImmlmppCOBz4DxwE8lja4scdRwTcWFQGdJg8zsnVDyONLMFgBtgKKw7srQJpION7N3gXcl/SfQjah3vVsMZrYFt4uKcvHgHQcyfPRisrJh/LMdWfphvI7aJ+rYuZTv37uQrGxDgrfG5jNtUnx7pUcfv4mzLizmk3+35IFX5gIw6jcHM/3NDmmObHcZ87eQogRtZkWEb+hmtknSB8CBRGXawWGzUcAkMixBt5A0h6phdk8Cvw2PPUb01WCWojrFaqKe79jQu50hqQR4FfhxYqNmVhLKEvdLakf02n8PLAB+ArwLLCUa4tcmPO0+ST2Ies0TgLnAvJpiSOUbkKz5Mzowf0b8/hkTTZ/YlukTM+NA25IPWzH0q/3SHUbSFsxsy/lH1PSFMJ7i/rfQwBNV8iXNSLg/Mnxr3r1dqTvQlyjHFITkjZkVSepSZ0wWx0r9PqZdbmcb1OGidIeRlPLiNekOoUGy28b3H74mVhbfcevVVWzdmu4QkvauTWCjrd2rYU2tO3WzY8/9XlLbTn3m1plm1r++7SS1Jhqc8Asze0nSejNrn/D4OjOrtZcV62F2zjnXZFI8DjqUTF8EnjazykEGnycM7y0kOrZWK0/QzjkXqCK5pd52ovLnn4APzOy3CQ+9Alwdbl8NjKmrnTjWoJ1zLj1SV/E9GfgGMD8cU4PouNi9wPOSrgOWAZfU1YgnaOecC1I1zM7MplB1/kZ1Zybbjido55yDUF+O16AJT9DOORf4qd7OORdDPmG/c87FlZmXOJxzLq68B+2cc3HlCdo55+LJe9DOORdHBpTHK0N7gnbOucB70M45F1c+isM55+LJe9DOORdHDZhKtKl4gm4KZlASv0vM7wvKN25Mdwj7rM2XnpjuEJJWMX7qXrchQH6Q0Dnn4kleg3bOuRjyEodzzsWVz8XhnHOx5aM4nHMurrwH7ZxzMWQ+isM55+IrXvnZE7RzzlXyYXbOORdXMUvQWekOwDnnYsGAiiSXekh6XNIqSe8lrOso6XVJi8LPDvW14wnaOecAYciSW5LwBHBetXW3ARPMrAcwIdyvkydo55yrVFGR3FIPM5sMrK22eggwKtweBVxQXzteg3bOOagqcSQnX9KMhPsjzWxkPc8pMLMiADMrktSlvp14gnbOuaABoziKzax/Y8YCXuJwzrkqZskte+ZzSYUA4eeq+p7gCdo554CdkyU1XoJ+Bbg63L4aGFPfE7zE4ZxzkNKrekt6BhhMVKv+FLgLuBd4XtJ1wDLgkvra8QSdYXLzKvjVU3PJzTOys40p4/N5esQh6Q6rVv0Hb+TGe1aQnWW89kxHnn+gIN0h1SmT4o17rLdfMYmTey1l3eYWfOOXlwJwRNc1/ODSybTIK6NobWvufvJMtu7IS3OkVVJ1JqGZXVHLQ2c2pJ1GK3FI6p44SDusGybp1jqe01/S/Y0QyzBJn0maEwaJvySpV6r30xRKS8Tt1/Tm5gv6cfOFfel/yjp6HhfPyz5lZRk3Df+MO688lG8N7snpQ9ZzcI/t6Q6rVpkUbybE+uq7R/I/j35xl3W3Xf4mD/9tIFf96hImzz+UK8+Ym6boatG4JY4Gi1UN2sxmmNl3Gqn535lZnzBI/DlgoqTOjbSvRiS2b80GICfHyM6piN0EL5V69t3KiiV5rFzWjLLSLCaNac+gczekO6xaZVK8mRDr3MVd2bi1+S7rDu6ynjkfFwIwfeFBnHbc4nSEVjMDKiy5pYmkJUFLmiTpl5KmSfpQ0hfC+sGS/h5ud5I0XtJsSY9KWiopv3rPXNKtkoaF24dLGitppqS3JB1V0/7N7DlgPPC18Lwzw37mh1M0m4X190p6X9I8Sb8O6zpLelHS9LCc3IhvVY2ysowRL89i9NtTmf2vDiyc17apQ0hKpwNKWb2i6utrcVEu+YXxvXhuJsWbSbEmWlzUkVOOWQrA6X0WU9B+S5ojStToBwkbLJ096BwzOwH4HlEBvbq7gClm1pfo6OfBSbQ5EhhqZscDtwIP1bHtLOAoSc2JTsu8zMyOJarL/7ekjsCFwNFm1hv4eXjeH4h64wOAi4DHampc0vWSZkiaUVKR2q+eFRVi6IX9uGrwQI7svYlDesTpj7yKtPu6mM1Fs4tMijeTYk00/JnTuOiUBfzp+y/SslkJpeWx+hIfuwTdmAcJa3sVletfCj9nAt1r2O5U4KsAZvYPSevq2pmk1sBJwAuq+uttVtdTws+ewCdm9mG4Pwq4CXgA2A48JukfwN/D42cBvRL20VZSGzPblNh4OKtoJEC7nPxG+Y1u2ZTD/GntOP4L61i6qFVj7GKvFBfl0rlryc77+YWlrFmZm8aI6pZJ8WZSrImWrerALY98CYBunddzUq9laY4ogQHlyZ9K2BQa8+NrDVB9tqaOQHG4vSP8LKf2D4qaElsZu8ZdWeTKAtaHOnPl8h91xNcX+ICqRL3rjs3KgBOAF4nOmR+bsJ9BCfs4sHpybkxtO5TQqk0ZAHnNyukzaD2fLm7RVLtvkIVzWnLgoSUUdNtBTm4Fg4esZ+r4dukOq1aZFG8mxZqofettAEjG1efM4q//itOxegOrSG5pIo3WgzazzZKKJJ1pZhNCyeA8ohLBtUk0MRm4Evi5pPOpSvafA10kdQI2A18GxprZRkmfSLrEzF5Q1MXtbWa7HSaWdBFwDvB9YBPQXdIRZvYR8A3gzdAjb2lmr0qaCnwUnj4euBm4L7TVx8zmNPgN2kMdO5fy/XsXkpVtSPDW2HymTerUVLtvkIpy8eAdBzJ89GKysmH8sx1Z+mHz+p+YJpkUbybEOuyqf9L38CLat97Oy8Oe4k+v9adFs1K+esoCAN6cdyj/eLdnmqOsJmZ1osYeB30V8KCk34T7d5vZx6qpgLa7u4FnJM0C3iQa2I2ZlUr6GfAu8Anw74TnXAk8LOlOIBd4FqhM0LdI+jrQCngPOMPMVgNIupaoNJIDTAceIertjwk1agG3hHa+E17TPKL3bzJwYwPek72y5MNWDP1qv6ba3V6bPrEt0yfG8yBmTTIp3rjHOuz/zqpx/QuTj23iSJJUOYojRmQx+8SojaQlQH8zK65v27hpl5Nvg1oPSXcYSSnfGM8x1a7pbb70xHSHkLT543/P5rXLk+r51aZdXoGdVHB5UtuO/fT+mU0xWZKfSeicc5Vi1mHNmARtZt3THYNzbh9mBuXl6Y5iFxmToJ1zrtF5D9o552LKE7RzzsVR086zkQxP0M45B2EqjnidSegJ2jnnKsXsVG9P0M45B1H9ucITtHPOxZMfJHTOuXgy70E751wcNe1cz8nwBO2ccxDLyZI8QTvnHFF+tpid6h2z680451yaWGon7Jd0nqSFkj6SdNuehOQ9aOecCyxFJQ5J2cCDwNnAp8B0Sa+Y2fsNacd70M45Vyl1PegTgI/MbLGZlRBdPKTBk8JnzIT9mUzSamBpIzSdT9U1HuMuk2KFzIo3k2KFxon3EDPrvDcNSBpLFFsymhNdVLrSyHCh6Mq2LgbOM7P/Cve/AQw0s5sbEpOXOJrA3v7h1EbSjKa4qkMqZFKskFnxZlKsEN94zey8FDZX09VdGtwb9hKHc86l3qdAt4T7BwErGtqIJ2jnnEu96UAPSYdKygMuB15paCNe4shsI+vfJDYyKVbIrHgzKVbIvHgbzMzKJN0MjAOygcfNbEFD2/GDhM45F1Ne4nDOuZjyBO2cczHlCTpmJN0haYGkeZLmSBoo6XuSWu5BW9dI6toYcSbsI2Xx7kUMm5tqX3tDUnl4jxZImivpfySl7X9QUndJ71VbN0zSrXU8p7+k+xshlmGSPgvvzyJJL0nqler9ZBo/SBgjkgYBXwb6mdkOSflAHvAc8BSwtQFtZQPXAO+xB8N7ktxHyuJNN0k5ZlbWyLvZZmZ9wv66AKOBdsBde9NoE8UOgJnNAGY0UvO/M7NfA0i6DJgo6VgzW91I+4s970HHSyFQbGY7AMysGLgY6Aq8IekNAEkPS5oRemJ3Vz5Z0hJJP5U0BbgC6A88HXolLdIY7xWS5kt6T9IvE+LdLOk3kmZJmiBpb88EGyxpkqS/SPq3pKclKTw2QNK/Qs91mqQ24RvGC5L+BoyX1ErS45KmS5otaUh4bndJb4U4Z0k6KawvlDQ5vL/vSfpCWH+OpHfCti9Ial09VjNbBVwP3KxItqT7wr7nSboh4XX9MLx/cyXdG9ZNkjRc0pvAdyUdL+lNSTMljZNUGLb7VmhzrqQXK7/ZSLqEaITB4ZImh3XZRHNHfDf8bsaG9+rDhNc2WNLfw+1OksaH9+pRSUsl5VfvmUu6VdKwcPvw0O7M8J4eVdPv0syeA8YDXwvPOzPsZ374HTUL6++V9H54zyqTe+fwWqeH5eQG/inFh5n5EpMFaA3MAT4EHgJOC+uXAPkJ23UMP7OBSUDvhO1+mLDdJKB/OuMlStbLgM5E39gmAheExwy4Mtz+KfDAHsaxOfwcDGwgOikgC3gHOIWoV78YGBC2axtiuYbohILK93M48PVwu314Xa2AlkDzsL4HMCPc/j5wR8Lvog3RqcKTgVZh/Y+AnybGWS32dUABUbK+M6xrRtRLPRQ4H/gX0LLa734S8FC4nRu26RzuX0Y0rAugU8K+fg4MDbfnAwOJvmG1D+uuD7+fW4E3gZUhhi8C/0x4j/8ebt+f8Nq+FH6f+UB34L2E/d4KDAu3JwA9wu2BwMRwexhwa7X35nvAw0SnVS8Hjgzr/y881hFYSNVotMrXMRo4Jdw+GPgg3f/be7p4iSNGzGyzpOOBLwCnA8+p5mkKL5V0PVGSKQR6AfPCY881SbAkHe8AYJKFr6mSngZOBf4KVCTE+xTwUgrCmmZmn4Z9zSFKFhuAIjObHuLeGB4HeN3M1obnngN8RVU12OZE/+ArgAck9QHKgSPD49OBxyXlAn81szmSTiP6fbwd2s8j+qCoTeUpwecAvRXN4QBR6aMHcBbwZzPbGmJfm/DcyveuJ3AM8HrYZzZQFB47RtLPiT5wWhP1mgHeBn4NdAjbV8ZwXGivHbAxxDAzvI/VnQp8NcT1D0nr6nidhG8SJwEvhDgh+jCq9SkJr+8TM/sw3B8F3AQ8QDQfxmOS/gH8PTx+FtArYR9tJbUxs011xRdHnqBjxszKiXpHkyTNB65OfFzSoUQ9kgFmtk7SE0SJpNKWJgoVqD9eap6ToNbmUhDSjoTb5UR/46qj7cT3S8BFZrYwcYPw9fxzouSVRZgkx8wmSzqVqPf4pKT7iHrEr5vZFfUFKumwEOOqsO+hZjau2jbnJRG7gAVmNqiGbZ4g+sYyV9I1RD1gzOxGSYOJzm6bEz58BLwFvAxcS9SjnaHo2EJtuaKm2MrYtXxa+feZBay3UIdPQl+ibxI1/g1ZdDLICcCZRGfq3QycEfYzyMy2Jbmf2PIadIxI6impR8KqPkSz4G0i+voM0dfzLcAGSQVEX4Frk/i8lEsy3neB00JtMpuoNv5meCyLqGYNUa1xSiOF+m+gq6QBIe42kmpKOOOAodLOunXfsL4dUQ+8AvgGoccp6RBglZn9EfgT0A+YCpws6YiwTUtJR1KNonr7I0RlHQv7/u/QG0fSkZJaEdVhv5lQO+5YQ9wLgc6KDtoiKVfS0eGxNkBRaPfKhP0fbmaTiMo424nmjXiLqPc5NWx2cIihNpMr25R0PlFvHKIPsy6hRt2M6EBy5TeXT0L9G0WOq6lhSRcR9eifIfr9da98T4l+B2+GHnk7M3uVqOTRJzw+nihZV7ZVuT7jeA86XloDIyS1J+qFfERUF7wCeE1SkZmdLmk2sICorvp2He09ATwiaRuN06NINt7bgTeIekKvmtmY8PwtwNGSZhKVIS5LcXwAmFmJolEBIxQdLN1GlIiquwf4PTAvJOklRMnlIeDFkFjeoKrnOhj4gaRSYDNwlZmtDj3VZyoPZAF3EiXCFqHskkv0fj0J/DZs8xhRGWFW2Pdqop7v2JBgZkgqAV4FflzD67sYuF9SO6L/698T/Y38hOhDcilR3bnyg/O+8OHaPCxPhPUTgL8Ah4X9TKj1jYW7w+ucRfShuyzEUyrpZ2G/nxAl2EpXAg9LujO8D88Cc8Njt0j6OlHd/z3gjITS2LVEpZEcotLSI0Q16DGSmhP9bd0S2vkO8KCkeeG9mAzcWMfriC0/1duljaTNZrbbCAeXmSQtIToonUlzU8ealziccy6mvAftnHMx5T1o55yLKU/QzjkXU56gnXMupjxBu7RT1Sxv7ymau2KPZ8KT9ETl2XiSHlMdM6IpmlfipD3Yx5Jw8kZS66tt06CZ91TP7HJu3+YJ2sXBNjPrY2bHACVUG7MaTnBpMDP7LzN7v45NBhOdeuxcLHmCdnHzFnBE6N2+IWk0MF+1zPYWzkZ7QNGMZv8AulQ2pGjGt/7h9nmKZpebq2jmvO5EHwS3hN77F1TLLGiqNmsbSZy+LumvimZsW6Bo3pTEx3abwU9JzvLm9i9+JqGLjXCW2PnA2LDqBOAYM/skJLkNZjYgnKH3tqTxRPM19ASOJZoV7n3g8Wrtdgb+CJwa2upoZmslPUI0w1zlNJWjieYkniLpYKLTr/+DaL7mKWb2M0lfIjpbsj7fDPtoAUyX9KKZrSE6S26WmX1f0k9D2zcTXUj1RjNbJGkg0dmLZ+zB2+j2IZ6gXRxUngINUQ/6T0Slh2lm9klYX9tsb6cCz4RJm1ZImlhD+ycCkyvbqjYjXKIaZ0GjgbO2Bd+RdGG43S3EuoYaZvBTw2d5c/sJT9AuDnZeaaRSSFTVZ5qraba3L1L/LHh1zWaXqMZZ0EIsSZ/RpWiWuLNCW1slTWLXGQcTGQ2f5c3tJ7wG7TJFbbO9TQYuDzXqQqJ5qat7h2hGvUPDcytnhKs+219ts6DVNmtbbdoB60JyPoqoB19ptxn8GjLLm9u/eIJ2meIxovryLEWXU3qU6Bvgy8AiopnaHqZqKtOdwoxo1xOVE+ZSVWL4G3Bh5UFColnQ+oeDkO9TNZrkbuBURbO2nUOYta0OY4GcMJvaPVRN3wm7zuB3BvCzsP5K4LoQ3wJgSBLvidvH+VwczjkXU96Dds65mPIE7ZxzMeUJ2jnnYsoTtHPOxZQnaOeciylP0M45F1OeoJ1zLqb+H6p/Ww+r7HgaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_model(\"action\", model_checkpoints[model_type], epochs=100, classification=\"token\", chunk_by=\"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abaafef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ef6f9c69d700c554\n",
      "Reusing dataset json (/home/brentdevries/.cache/huggingface/datasets/json/default-ef6f9c69d700c554/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning data preprocessing\n",
      "Processed data written to action_sentence_train_for_sequence_classification.json and action_sentence_dev_for_sequence_classification.json\n",
      "Train label distribution:\n",
      "Start: 436\n",
      "Stop: 270\n",
      "Increase: 97\n",
      "Decrease: 31\n",
      "UniqueDose: 258\n",
      "Dev label distribution:\n",
      "Start: 83\n",
      "Stop: 56\n",
      "Increase: 23\n",
      "Decrease: 9\n",
      "UniqueDose: 22\n",
      "Loading dataset into huggingface format\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686a9dbf3d544f53ac8d7632a94bff17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets using BERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/brentdevries/.cache/huggingface/datasets/json/default-ef6f9c69d700c554/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-af1652511dce6e8b.arrow\n",
      "Loading cached processed dataset at /home/brentdevries/.cache/huggingface/datasets/json/default-ef6f9c69d700c554/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-7aa0faae1549b0ef.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BERT sequence classification model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running training *****\n",
      "  Num examples = 1092\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model sent to cuda\n",
      "Setting up training configuration\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1360' max='1360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1360/1360 14:09, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.643298</td>\n",
       "      <td>0.145078</td>\n",
       "      <td>0.145078</td>\n",
       "      <td>0.089434</td>\n",
       "      <td>0.145078</td>\n",
       "      <td>0.203916</td>\n",
       "      <td>0.145078</td>\n",
       "      <td>0.121084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.588081</td>\n",
       "      <td>0.264249</td>\n",
       "      <td>0.264249</td>\n",
       "      <td>0.093479</td>\n",
       "      <td>0.264249</td>\n",
       "      <td>0.209740</td>\n",
       "      <td>0.264249</td>\n",
       "      <td>0.124835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.520837</td>\n",
       "      <td>0.264249</td>\n",
       "      <td>0.264249</td>\n",
       "      <td>0.151354</td>\n",
       "      <td>0.264249</td>\n",
       "      <td>0.243729</td>\n",
       "      <td>0.264249</td>\n",
       "      <td>0.164399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.470222</td>\n",
       "      <td>0.378238</td>\n",
       "      <td>0.378238</td>\n",
       "      <td>0.168193</td>\n",
       "      <td>0.378238</td>\n",
       "      <td>0.194203</td>\n",
       "      <td>0.378238</td>\n",
       "      <td>0.164265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.433603</td>\n",
       "      <td>0.445596</td>\n",
       "      <td>0.445596</td>\n",
       "      <td>0.302659</td>\n",
       "      <td>0.445596</td>\n",
       "      <td>0.275493</td>\n",
       "      <td>0.445596</td>\n",
       "      <td>0.254981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.354554</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>0.302278</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>0.326756</td>\n",
       "      <td>0.471503</td>\n",
       "      <td>0.293686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.292786</td>\n",
       "      <td>0.466321</td>\n",
       "      <td>0.466321</td>\n",
       "      <td>0.275777</td>\n",
       "      <td>0.466321</td>\n",
       "      <td>0.365013</td>\n",
       "      <td>0.466321</td>\n",
       "      <td>0.305438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.458200</td>\n",
       "      <td>1.172170</td>\n",
       "      <td>0.518135</td>\n",
       "      <td>0.518135</td>\n",
       "      <td>0.460291</td>\n",
       "      <td>0.518135</td>\n",
       "      <td>0.438236</td>\n",
       "      <td>0.518135</td>\n",
       "      <td>0.412401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.458200</td>\n",
       "      <td>0.962542</td>\n",
       "      <td>0.647668</td>\n",
       "      <td>0.647668</td>\n",
       "      <td>0.529185</td>\n",
       "      <td>0.647668</td>\n",
       "      <td>0.541525</td>\n",
       "      <td>0.647668</td>\n",
       "      <td>0.533042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.458200</td>\n",
       "      <td>0.835322</td>\n",
       "      <td>0.683938</td>\n",
       "      <td>0.683938</td>\n",
       "      <td>0.536984</td>\n",
       "      <td>0.683938</td>\n",
       "      <td>0.595737</td>\n",
       "      <td>0.683938</td>\n",
       "      <td>0.559577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.458200</td>\n",
       "      <td>0.750249</td>\n",
       "      <td>0.720207</td>\n",
       "      <td>0.720207</td>\n",
       "      <td>0.563800</td>\n",
       "      <td>0.720207</td>\n",
       "      <td>0.603017</td>\n",
       "      <td>0.720207</td>\n",
       "      <td>0.582504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.458200</td>\n",
       "      <td>0.793572</td>\n",
       "      <td>0.735751</td>\n",
       "      <td>0.735751</td>\n",
       "      <td>0.582519</td>\n",
       "      <td>0.735751</td>\n",
       "      <td>0.639189</td>\n",
       "      <td>0.735751</td>\n",
       "      <td>0.602145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.458200</td>\n",
       "      <td>0.747399</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.591302</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.624856</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.605990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.458200</td>\n",
       "      <td>0.746534</td>\n",
       "      <td>0.777202</td>\n",
       "      <td>0.777202</td>\n",
       "      <td>0.753219</td>\n",
       "      <td>0.777202</td>\n",
       "      <td>0.704772</td>\n",
       "      <td>0.777202</td>\n",
       "      <td>0.702427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.591300</td>\n",
       "      <td>0.750133</td>\n",
       "      <td>0.756477</td>\n",
       "      <td>0.756477</td>\n",
       "      <td>0.733401</td>\n",
       "      <td>0.756477</td>\n",
       "      <td>0.687291</td>\n",
       "      <td>0.756477</td>\n",
       "      <td>0.695743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.591300</td>\n",
       "      <td>0.782061</td>\n",
       "      <td>0.766839</td>\n",
       "      <td>0.766839</td>\n",
       "      <td>0.728138</td>\n",
       "      <td>0.766839</td>\n",
       "      <td>0.734931</td>\n",
       "      <td>0.766839</td>\n",
       "      <td>0.725815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.591300</td>\n",
       "      <td>0.794836</td>\n",
       "      <td>0.766839</td>\n",
       "      <td>0.766839</td>\n",
       "      <td>0.700519</td>\n",
       "      <td>0.766839</td>\n",
       "      <td>0.738127</td>\n",
       "      <td>0.766839</td>\n",
       "      <td>0.710726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.591300</td>\n",
       "      <td>0.862228</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.708676</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.677758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.591300</td>\n",
       "      <td>0.956337</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.654316</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.706352</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.674042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.591300</td>\n",
       "      <td>0.957393</td>\n",
       "      <td>0.751295</td>\n",
       "      <td>0.751295</td>\n",
       "      <td>0.680714</td>\n",
       "      <td>0.751295</td>\n",
       "      <td>0.724612</td>\n",
       "      <td>0.751295</td>\n",
       "      <td>0.695036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to cmed-action/checkpoint-500\n",
      "Configuration saved in cmed-action/checkpoint-500/config.json\n",
      "Model weights saved in cmed-action/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-action/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in cmed-action/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to cmed-action/checkpoint-1000\n",
      "Configuration saved in cmed-action/checkpoint-1000/config.json\n",
      "Model weights saved in cmed-action/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-action/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in cmed-action/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10253/3830641789.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"action\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_checkpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/nlp-final/run_model.py\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(task, model_checkpoint, epochs, batch_size, lr, scheduler, dropout, classification, chunk_by, split, chunk_size)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mlabel_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint2label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mprint_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCMEDTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nlp-final/run_model.py\u001b[0m in \u001b[0;36mprint_confusion_matrix\u001b[0;34m(trainer, tokenized_data, classification, label_names)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "run_model(\"action\", model_checkpoints[model_type], epochs=20, lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "792d76cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning data preprocessing\n",
      "Processed data written to action_sentence_train_for_sequence_classification.json and action_sentence_dev_for_sequence_classification.json\n",
      "Train label distribution:\n",
      "Start: 436\n",
      "Stop: 270\n",
      "Increase: 97\n",
      "Decrease: 31\n",
      "UniqueDose: 258\n",
      "Dev label distribution:\n",
      "Start: 83\n",
      "Stop: 56\n",
      "Increase: 23\n",
      "Decrease: 9\n",
      "UniqueDose: 22\n",
      "Loading dataset into huggingface format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ef6f9c69d700c554\n",
      "Reusing dataset json (/home/brentdevries/.cache/huggingface/datasets/json/default-ef6f9c69d700c554/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59be8402b5144ac850f47a0b29931d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing datasets using BERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/brentdevries/.cache/huggingface/datasets/json/default-ef6f9c69d700c554/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-af1652511dce6e8b.arrow\n",
      "Loading cached processed dataset at /home/brentdevries/.cache/huggingface/datasets/json/default-ef6f9c69d700c554/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-7aa0faae1549b0ef.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BERT sequence classification model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running training *****\n",
      "  Num examples = 1092\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model sent to cuda\n",
      "Setting up training configuration\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1360' max='1360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1360/1360 14:49, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Micro F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.766397</td>\n",
       "      <td>0.082902</td>\n",
       "      <td>0.082902</td>\n",
       "      <td>0.033743</td>\n",
       "      <td>0.082902</td>\n",
       "      <td>0.220290</td>\n",
       "      <td>0.082902</td>\n",
       "      <td>0.056709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.714380</td>\n",
       "      <td>0.098446</td>\n",
       "      <td>0.098446</td>\n",
       "      <td>0.036019</td>\n",
       "      <td>0.098446</td>\n",
       "      <td>0.219324</td>\n",
       "      <td>0.098446</td>\n",
       "      <td>0.061632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.628983</td>\n",
       "      <td>0.134715</td>\n",
       "      <td>0.134715</td>\n",
       "      <td>0.303497</td>\n",
       "      <td>0.134715</td>\n",
       "      <td>0.235444</td>\n",
       "      <td>0.134715</td>\n",
       "      <td>0.088922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.536593</td>\n",
       "      <td>0.398964</td>\n",
       "      <td>0.398964</td>\n",
       "      <td>0.106487</td>\n",
       "      <td>0.398964</td>\n",
       "      <td>0.198114</td>\n",
       "      <td>0.398964</td>\n",
       "      <td>0.137021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.466829</td>\n",
       "      <td>0.430052</td>\n",
       "      <td>0.430052</td>\n",
       "      <td>0.086010</td>\n",
       "      <td>0.430052</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.430052</td>\n",
       "      <td>0.120290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.426644</td>\n",
       "      <td>0.435233</td>\n",
       "      <td>0.435233</td>\n",
       "      <td>0.286458</td>\n",
       "      <td>0.435233</td>\n",
       "      <td>0.209091</td>\n",
       "      <td>0.435233</td>\n",
       "      <td>0.138119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.397483</td>\n",
       "      <td>0.487047</td>\n",
       "      <td>0.487047</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>0.487047</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.487047</td>\n",
       "      <td>0.258053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.594500</td>\n",
       "      <td>1.329487</td>\n",
       "      <td>0.512953</td>\n",
       "      <td>0.512953</td>\n",
       "      <td>0.352729</td>\n",
       "      <td>0.512953</td>\n",
       "      <td>0.359396</td>\n",
       "      <td>0.512953</td>\n",
       "      <td>0.307001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.594500</td>\n",
       "      <td>1.266257</td>\n",
       "      <td>0.466321</td>\n",
       "      <td>0.466321</td>\n",
       "      <td>0.273220</td>\n",
       "      <td>0.466321</td>\n",
       "      <td>0.352813</td>\n",
       "      <td>0.466321</td>\n",
       "      <td>0.300861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.594500</td>\n",
       "      <td>1.174056</td>\n",
       "      <td>0.487047</td>\n",
       "      <td>0.487047</td>\n",
       "      <td>0.290085</td>\n",
       "      <td>0.487047</td>\n",
       "      <td>0.364775</td>\n",
       "      <td>0.487047</td>\n",
       "      <td>0.314952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.594500</td>\n",
       "      <td>1.045675</td>\n",
       "      <td>0.554404</td>\n",
       "      <td>0.554404</td>\n",
       "      <td>0.453697</td>\n",
       "      <td>0.554404</td>\n",
       "      <td>0.466408</td>\n",
       "      <td>0.554404</td>\n",
       "      <td>0.447845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.594500</td>\n",
       "      <td>0.908133</td>\n",
       "      <td>0.652850</td>\n",
       "      <td>0.652850</td>\n",
       "      <td>0.517473</td>\n",
       "      <td>0.652850</td>\n",
       "      <td>0.547791</td>\n",
       "      <td>0.652850</td>\n",
       "      <td>0.531583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.594500</td>\n",
       "      <td>0.875842</td>\n",
       "      <td>0.678756</td>\n",
       "      <td>0.678756</td>\n",
       "      <td>0.527921</td>\n",
       "      <td>0.678756</td>\n",
       "      <td>0.588970</td>\n",
       "      <td>0.678756</td>\n",
       "      <td>0.549698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.594500</td>\n",
       "      <td>0.801900</td>\n",
       "      <td>0.694301</td>\n",
       "      <td>0.694301</td>\n",
       "      <td>0.536698</td>\n",
       "      <td>0.694301</td>\n",
       "      <td>0.604331</td>\n",
       "      <td>0.694301</td>\n",
       "      <td>0.564926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.859700</td>\n",
       "      <td>0.749088</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.573396</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.624379</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.596533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.859700</td>\n",
       "      <td>0.771755</td>\n",
       "      <td>0.730570</td>\n",
       "      <td>0.730570</td>\n",
       "      <td>0.562765</td>\n",
       "      <td>0.730570</td>\n",
       "      <td>0.628170</td>\n",
       "      <td>0.730570</td>\n",
       "      <td>0.589767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.859700</td>\n",
       "      <td>0.766033</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.583825</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.642557</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.608819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.859700</td>\n",
       "      <td>0.819901</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.588300</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.644114</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>0.609470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.859700</td>\n",
       "      <td>0.860360</td>\n",
       "      <td>0.756477</td>\n",
       "      <td>0.756477</td>\n",
       "      <td>0.626145</td>\n",
       "      <td>0.756477</td>\n",
       "      <td>0.673870</td>\n",
       "      <td>0.756477</td>\n",
       "      <td>0.640975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.859700</td>\n",
       "      <td>0.853365</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.647636</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.686454</td>\n",
       "      <td>0.740933</td>\n",
       "      <td>0.659520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to cmed-action/checkpoint-500\n",
      "Configuration saved in cmed-action/checkpoint-500/config.json\n",
      "Model weights saved in cmed-action/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-action/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in cmed-action/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to cmed-action/checkpoint-1000\n",
      "Configuration saved in cmed-action/checkpoint-1000/config.json\n",
      "Model weights saved in cmed-action/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in cmed-action/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in cmed-action/checkpoint-1000/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_model(\"action\", model_checkpoints[model_type], epochs=20, lr=3e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
